{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformée en Ondelettes 2D, application au traitement des images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <Font color = \"blue\"> ENGELSEN Gorm et RAHAL Skander"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as scp\n",
    "import pylab as pyl\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "import param\n",
    "import panel as pn\n",
    "from panel.pane import LaTeX\n",
    "hv.extension('bokeh')\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import requests\n",
    "import boto3\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_endpoint_url = 'https://object-rook-ceph.apps.math.cnrs.fr/'\n",
    "s3_access_key_id = '9F7EB8YBUWXDV7A4IZYW' # le contenu de secrets/dossal\n",
    "s3_secret_access_key = 'skV01Eei5M3xVOxROIDr3qymYhWtkrxPpMyj8nwb' # le contenu de secrets/dossal\n",
    "s3_bucket = 'signal-image'\n",
    "s3 = boto3.client('s3',\n",
    "                  '',\n",
    "                  endpoint_url = s3_endpoint_url,\n",
    "                  aws_access_key_id = s3_access_key_id,\n",
    "                  aws_secret_access_key = s3_secret_access_key)\n",
    "Data=[\"Lenna.jpg\",\"Canaletto.jpeg\",\"MinotaureBruite.jpeg\",\"Cartoon.jpg\"]\n",
    "if not os.path.isfile('Lenna.jpg'):\n",
    "    for filenames in Data:  \n",
    "        s3.download_file(s3_bucket,filenames,filenames)\n",
    "def chargeData(name):\n",
    "    if name=='Lenna':\n",
    "        res=np.array(Image.open(\"Lenna.jpg\")).astype(float)\n",
    "    if name=='Canaletto':\n",
    "        res=np.array(Image.open(\"Canaletto.jpeg\")).astype(float)\n",
    "    if name=='Minotaure':\n",
    "        res=np.array(Image.open(\"MinotaureBruite.jpeg\")).astype(float)  \n",
    "    if name=='Cartoon':\n",
    "        res=np.array(Image.open(\"Cartoon.jpg\")).astype(float) \n",
    "    return res\n",
    "options1=dict(width=400,height=400,xaxis=None,yaxis=None,toolbar=None)\n",
    "options2=dict(width=700,height=400,xaxis=None,yaxis=None,toolbar=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximation linéaire et non linéaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im2=chargeData('Lenna')\n",
    "im=chargeData('Canaletto')\n",
    "imagesRef= {\"Lenna\" : im2,\"Canaletto\" : im}\n",
    "options = dict(cmap='gray',xaxis=None,yaxis=None,width=400,height=400,toolbar=None)\n",
    "pn.Row(hv.Raster(imagesRef[\"Lenna\"]).opts(**options),hv.Raster(imagesRef[\"Canaletto\"]).opts(**options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=400\n",
    "WT= pywt.wavedecn(im, 'haar', mode='per', level=2)\n",
    "arr, coeff_slices = pywt.coeffs_to_array(WT)\n",
    "hv.Image(arr).opts(cmap='gray',width=size,height=size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui réalise une approxiamtion non linéaire en seuillant les coefficients d'ondelettes.\n",
    "On pourra utiliser les fonctions suivante : pywt.coeffs_to_array et pywt.array_to_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ApproxOnd2D(S,qmf,L,threshold):\n",
    "    Lmax=pywt.dwt_max_level(len(S),pywt.Wavelet(qmf).dec_len) \n",
    "    L1=min(L,Lmax)\n",
    "    WT= pywt.wavedecn(S, qmf, mode='per', level=L1)\n",
    "    arr, coeff_slices = pywt.coeffs_to_array(WT) \n",
    "    WTS=arr*(np.abs(arr)>threshold)\n",
    "    coeffs_from_arr = pywt.array_to_coeffs(WTS, coeff_slices) \n",
    "    Srec=pywt.waverecn(coeffs_from_arr,qmf,mode='per')\n",
    "    ncoeffs = len(np.where(WTS !=0)[0])\n",
    "    return Srec,ncoeffs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "Srec,ncoef=ApproxOnd2D(im2,'Haar',9,20)\n",
    "print(ncoef)\n",
    "pn.Row(hv.Image(im,label=\"image originale\").opts(**options),hv.Image(Srec,label=\"image après approximation linéaire\").opts(**options))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>On remarque que l'image obtenue après approximation linéaire est de moins bonne qualité que l'image originale car on ne conserve que des coefficients d'ondelette supérieurs à un certain threshold.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une focntion PSNR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(I,Iref):\n",
    "    temp=I.ravel()\n",
    "    tempref=Iref.ravel()\n",
    "    NbP=I.size\n",
    "    EQM=np.sum((temp-tempref)**2)/NbP\n",
    "    b=np.max(np.abs(tempref))**2\n",
    "    return 10*np.log10(b/EQM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psnr=PSNR(im2,Srec)\n",
    "print(psnr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui réalise une approximation non linéaire en conservant un nombre N de coefficients d'ondelettes et la tester. On pourra utiliser les fonctions pywt.ravel_coeffs et unravel_coeffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ApproxOnd2nonlin(I,qmf,L,N):\n",
    "    n,m=np.shape(I)\n",
    "    Lmax=pywt.dwt_max_level(len(I),pywt.Wavelet(qmf).dec_len)\n",
    "    L1=min(L,Lmax)\n",
    "    WT= pywt.wavedecn(I, qmf, mode='per', level=L1)\n",
    "    arr, coeff_slices = pywt.coeffs_to_array(WT)\n",
    "    arr_vector=arr\n",
    "    arr_vector=arr_vector.flatten()\n",
    "    N1=len(arr_vector)\n",
    "    Ind=np.argsort(np.abs(arr_vector))\n",
    "    WTS=np.zeros(N1)\n",
    "    WTS[Ind[N1-N:N1]]=arr_vector[Ind[N1-N:N1]]\n",
    "    WTS=WTS.reshape(n,m)\n",
    "    coeffs_from_arr = pywt.array_to_coeffs(WTS, coeff_slices)\n",
    "    Irec=pywt.waverecn(coeffs_from_arr,qmf,mode='per')\n",
    "    p=PSNR(I,Irec)\n",
    "    return Irec,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Irec,p=ApproxOnd2nonlin(im,'db2',6,5000)\n",
    "pn.Row(hv.Image(im,label=\"image originale\").opts(**options),hv.Image(Irec,label=\"image après approximation non linéaire\").opts(**options))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>On remarque que l'image obtenue après approximation non linéaire est de moins bonnes qualité que l'image originale comme dans la cas de l'approximation linéaire car on ne conserve qu'un nombre fini des plus grands coefficients d'ondelettes (ici N=5000). Ici on utilise la base de daubechies ,c'est pour cela qu'on obtient pas le même résultat que pour la base de haar.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un Dashboard qui permet d'explorer la fonction précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelist=['haar','db2','db3','db4','coif1','coif2','coif3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Approxnonlin2D(param.Parameterized):\n",
    "    image = param.ObjectSelector(default=\"Canaletto\",objects=imagesRef.keys())\n",
    "    wave = param.ObjectSelector(default=\"haar\",objects=wavelist)\n",
    "    L = param.Integer(5,bounds=(0,7))\n",
    "    N = param.Integer(2000,bounds=(1,10000))\n",
    "  #  @param.depends('wave', 'N', 'L')\n",
    "    def view(self):\n",
    "        Iref=imagesRef[self.image]\n",
    "        Irec,p = ApproxOnd2nonlin(Iref,self.wave,self.L,self.N)\n",
    "        Image_originale=hv.Image(Iref,label=\"image originale\").opts(cmap='gray',width=300,height=300)\n",
    "        Image_aprox=hv.Image(Irec,label=\"image approximation non linéaire\").opts(cmap='gray',width=300,height=300)\n",
    "        return pn.Row(pn.Column(Image_originale,'PSNR pour approximation non linéaire',p),pn.Column(Image_aprox))\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approxno2D = Approxnonlin2D()\n",
    "pn.Row(approxno2D.param,approxno2D.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'> On remarque dans le cas d'une approximation non linéaire, lorsqu'on augmente la valeur de N,la valeur de PSNR est beaucoup plus importante et la qualité d'image s'améliore lorsque la valeur de celle-ci augmente.\n",
    "De plus, dans le cadre des ondelettes de daubechies , la velur de PSNR est plus élevée comparant aux ondelettes de Haar.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Approxlin2D(param.Parameterized):\n",
    "    image = param.ObjectSelector(default=\"Canaletto\",objects=imagesRef.keys())\n",
    "    wave = param.ObjectSelector(default=\"haar\",objects=wavelist)\n",
    "    L = param.Integer(5,bounds=(0,7))\n",
    "    T = param.Number(1,bounds=(1,100))\n",
    "  #  @param.depends('wave', 'N', 'L')\n",
    "    def view(self):\n",
    "        Iref=imagesRef[self.image]\n",
    "        Irec,ncoef = ApproxOnd2D(Iref,self.wave,self.L,self.T)\n",
    "        p=PSNR(Iref,Irec)\n",
    "        Image_originale=hv.Image(Iref,label=\"image originale\").opts(cmap='gray',width=300,height=300)\n",
    "        Image_aprox=hv.Image(Irec,label=\"image approximation linéaire\").opts(cmap='gray',width=300,height=300)\n",
    "        return pn.Row(pn.Column(Image_originale,'PSNR pour approximation linéaire',p),pn.Column(Image_aprox,'nombre de coefficients',ncoef))\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approx2D = Approxlin2D()\n",
    "pn.Row(approx2D.param,approx2D.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>Le coefficient L (profondeur de la transformée en ondelettes) a peu d'influence sur l'image obtenue après approximation non linéaire.\n",
    "Cependant, le coefficient de seuillage T agit sur la résultante. En effet , on remarque que la valeur de PSNR varie fortement en modifiant la valeur de T.\n",
    "On remarque aussi qu'avec une base de Haar, le PSNR ainsi que le nombre de coefficients sont beaucoup plus faibles que dans le cadre des ondelettes de Daubechies.( C'est pourcela la qualité d'image est meilleure dans le cadre des ondelettes de Daubechies par rapport aux ondelettes de Haar pour des valeurs de T et L fixées)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un plan d'experiences qui permet d'explorer la fonction ApproxOnd2nonlin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "wavelist = ['haar','db2','db3','db4','coif1','coif2','coif3']\n",
    "experiences = {'Image':imagesRef,'N':np.linspace(1000,50000,30),'wave':wavelist}\n",
    "dfexp=pd.DataFrame(data=itertools.product(*experiences.values()),columns=experiences.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(dfexp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer la fonction qui à une ligne de la base de donnée précédente calcule le PSNR associé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row2PSNR(row):\n",
    "    L=7\n",
    "    qmf=row[2]\n",
    "    N=int(row[1])\n",
    "    if row[1]=='Lenna':\n",
    "        Irec,p=ApproxOnd2nonlin(im2,qmf,L,N)\n",
    "    else:\n",
    "        Irec,p=ApproxOnd2nonlin(im,qmf,L,N)\n",
    "    return {'PSNR':p}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquer la fonction sur la base de donnée et ajouter la colonne PSNR à la base de données dfexp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = dfexp.iloc[0,:] \n",
    "p=row2PSNR(row)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=dfexp.apply(row2PSNR,axis='columns')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfexp=dfexp.assign(PSNR=pd.DataFrame.from_records(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfexp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliser hvplot pour visualiser la base de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models import HoverTool\n",
    "h = HoverTool()\n",
    "dfexp.hvplot('N','PSNR',by='wave',kind='scatter',groupby=['Image'],label = \"Tracé du PSNR en fonction du nombre de coefficients \\n d'ondelettes pour différentes bases d'ondelettes \\n \\n\" )\\\n",
    ".opts(width=600,tools = [h]).redim.range(PSNR=(20,45),N=(1000.0,50000.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "<font color='green'>On remarque que lorsqu'on augmente la valeur de N , la valeur de PSNR augmente aussi.\n",
    "De plus , on remarque que les ondelettes de coifmann donnent la meilleure approximation contrairement aux ondelettes de haar qui sont les moins bonnes car admettant un PSNR plus faible que les autres.</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Débruitage d'images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui effectue un seuillage dur en ondelettes et la tester. On pourra utiliser la fonction pywt.ravel_coeffs et on pensera à cliper le résultat entre 0 et 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SeuillageDurOndelettes(I,qmf,L,Seuil):\n",
    "    Lmax=pywt.dwt_max_level(len(I),pywt.Wavelet(qmf).dec_len) #level de la TFO\n",
    "    L=min(L,Lmax)\n",
    "    WTB= pywt.wavedecn(I, qmf, mode='per', level=L)\n",
    "    arr, coeff_slices,coeff_shapes = pywt.ravel_coeffs(WTB)\n",
    "    WTS=arr*(np.abs(arr)>Seuil)\n",
    "    coeffs_from_arr = pywt.unravel_coeffs(WTS, coeff_slices,coeff_shapes)\n",
    "    Irec=pywt.waverecn(coeffs_from_arr,qmf,mode='per')\n",
    "\n",
    "    return Irec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construire un dashboard qui permet d'explorer la fonction SeuillageDurOndelettes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveSeuillage(param.Parameterized):\n",
    "    image = param.ObjectSelector(default=\"Canaletto\",objects=imagesRef.keys())\n",
    "    wave = param.ObjectSelector(default=\"haar\",objects=wavelist)\n",
    "    L = param.Integer(7,bounds=(0,7))\n",
    "    Seuil = param.Number(10,bounds=(1,1000))\n",
    "    def view(self):\n",
    "        Iref = imagesRef[self.image]\n",
    "        Irec = SeuillageDurOndelettes(Iref,self.wave,self.L,self.Seuil)\n",
    "        \n",
    "        Ioriginale = hv.Image(Iref,label=\"Image originale\").opts(cmap='gray',width=350,height=350)\n",
    "        Iapprox = hv.Image(Irec,label=\"Approximation non linéaire \\n par seuillage dur\").opts(cmap='gray',width=350,height=350)\n",
    "        \n",
    "\n",
    "        P = PSNR(Iref,Irec)\n",
    "        return pn.Row(Ioriginale,pn.Column (Iapprox, \"PSNR de l'image par approximation non linéaire : \",P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dash3=WaveSeuillage()\n",
    "pn.Row(dash3.param,dash3.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>Comme dans les autres cas, la valeur de L agit de manière très faible sur l'image.\n",
    "Lorsqu'on augmente la valeur du seuil ,l'image se dégrade de plus en plus car la valeur de PSNR diminue.\n",
    "Les ondelettes de Haar donnent des valeurs PSNR plus faibles que les ondelettes de daubechies et celles de coifman vu que celles ci sont des fonctions constantes par morceau (on remarque des rectangles prononcés sur l'image lorsque la valeur du seuil est élevée).</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bruit(im,sigma,seednoise):\n",
    "    np.random.seed(seed=seednoise)\n",
    "    n1,n2=np.shape(im)\n",
    "    B=np.random.randn(n1,n2)\n",
    "    ib=im+sigma*B\n",
    "    ib=np.clip(ib,0,255)\n",
    "    return ib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ib = Bruit(im,100,2)\n",
    "pn.Row(hv.Image(im,label=\"Image originale\").opts(cmap='gray',width=300,height=300),hv.Image(ib,label=\"Image bruitée\").opts(cmap='gray',width=300,height=300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Debruit(im,qmf,L,T,seednoise,sigma): \n",
    "\n",
    "    n1,n2=np.shape(im)\n",
    "  \n",
    "    Lmax=pywt.dwt_max_level(len(im),pywt.Wavelet(qmf).dec_len) #level de la TFO\n",
    "    L=min(L,Lmax)\n",
    "     \n",
    "    ib = Bruit(im,sigma,seednoise)\n",
    "\n",
    "    Seuil=T*sigma\n",
    "    Irec=SeuillageDurOndelettes(ib,qmf,L,Seuil)\n",
    "    \n",
    "    psnr1=PSNR(ib,im) \n",
    "    psnr2=PSNR(Irec,im)\n",
    "    return Irec,ib,psnr1,psnr2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire un dashboard qui permet de visualiser rapidement l'effet d'un débruitage en ondelettes et qui renvoie les images originales, bruitées et débruitées ainsi que les PSNR associés aux images bruitéeset débruitées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveDebruit(param.Parameterized):\n",
    "    image = param.ObjectSelector(default=\"Lenna\",objects=imagesRef.keys()) \n",
    "    wave = param.ObjectSelector(default=\"haar\",objects=wavelist)\n",
    "    L = param.Integer(7,bounds=(0,7))\n",
    "    Seuil = param.Number(3,bounds=(1,6))\n",
    "    Sigma = param.Number(10,bounds=(1,100)) \n",
    "    seednoise = param.Integer(1,bounds=(0,50))\n",
    "    T=param.Number(3,bounds=(0,8))\n",
    "    def view(self):\n",
    "        S = imagesRef[self.image]\n",
    "        Srec,SB,p1,p2=Debruit(S,self.wave,self.L,self.T,self.seednoise,self.Sigma)\n",
    "             \n",
    "    \n",
    "        Ioriginal = hv.Image(S, label = \"Image orinigale\").opts(cmap='gray',width=350,height=350)\n",
    "        Ibuite = hv.Image(SB,label = \"Image bruitée\").opts(cmap='gray',width=350,height=350) \n",
    "        Idebruite = hv.Image(Srec,label = \"Image débruitée\").opts(cmap='gray',width=350,height=350)\n",
    "        \n",
    "        return pn.Column(pn.Row(Ioriginal,pn.Column (Ibuite, \"PSNR entre image bruitée et image originale: \",p1),pn.Column (Idebruite, \"PSNR entre image débruitée et image originale: \",p2)))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wavedebruit = WaveDebruit()\n",
    "pn.Row(wavedebruit.param,wavedebruit.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>On remarque que le coefficient L a peu d'influence sur la qualité de l'approximation comme dans les autres cas.\n",
    "De plus , lorsqu'on ajoute du bruit à une image , la qualité de celle-ci diminue ce qui explique que la valeur de PSNR est plus faible pour une image bruité comparant à une image non bruitée.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Débruitage d'images et translations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui réalise un débruitage avec une moyenne sur des NbT fois NbT translations et la tester. Vérifier le gain en PNSR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DebruitTrans(im,qmf,L,T,seednoise,sigma,NbT):\n",
    "    \n",
    "    n1,n2=np.shape(im)\n",
    "    \n",
    "     #profondeur maximal de la TFO\n",
    "    Lmax=pywt.dwt_max_level(len(im),pywt.Wavelet(qmf).dec_len) #level de la TFO\n",
    "    L=min(L,Lmax)\n",
    "    \n",
    "    # bruitage de l'image : \n",
    "    ib = Bruit(im,sigma,seednoise)\n",
    "    \n",
    "    # débruitage de l'image\n",
    "    Seuil=T*sigma\n",
    "    ISum=0*ib\n",
    "    P=np.zeros(NbT)\n",
    "    \n",
    "    for k in np.arange(0,NbT): \n",
    "        #Translation des lignes et des colonnes de l'image\n",
    "        SBtemp=np.roll(ib,k,axis = 1) #décalage des colonnes\n",
    "        SBtemp=np.roll(SBtemp,k,axis = 0) #décalage des lignes\n",
    "        #Seuillage sur l'image translatée\n",
    "        Srectemp=SeuillageDurOndelettes(SBtemp,qmf,L,Seuil)\n",
    "        #Translation des lignes et des colonnes inverse\n",
    "        Srectemp2=np.roll(Srectemp,-k,axis = 1)\n",
    "        Srectemp2=np.roll(Srectemp2,-k,axis = 0)      \n",
    "\n",
    "        ISum=ISum+Srectemp2\n",
    "        Srec=ISum/(k+1)\n",
    "        P[k]=PSNR(Srec,im) #PSNR(I,Iref) de chaque translation\n",
    "    P_moy = np.mean(P) #moyenne des PNSR des images reconstruite \n",
    "    P_Buite=PSNR(ib,im) #PSNR(I,Iref) PNSR image bruitée\n",
    "    \n",
    "    return Srec,ib,P,P_moy,P_Buite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un dasboard pour explorer la fonction précédente. La sortie doit aussi être composée de 3 images et 2 PSNR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Debruit_translat(param.Parameterized):\n",
    "    image = param.ObjectSelector(default=\"Canaletto\",objects=imagesRef.keys())\n",
    "    wave = param.ObjectSelector(default=\"haar\",objects=wavelist)\n",
    "    NbT = param.Integer(4,bounds=(1,8))\n",
    "    Sigma = param.Number(10,bounds=(1,100))\n",
    "    seednoise = param.Integer(1,bounds=(0,50))\n",
    "    L = param.Integer(7,bounds=(0,7))\n",
    "    T=param.Number(3,bounds=(0,8))\n",
    "    def view(self):\n",
    "        S=imagesRef[self.image]\n",
    "        Srec,SB,P,P_moy,P_Buite=DebruitTrans(S,self.wave,self.L,self.T,self.seednoise,self.Sigma,self.NbT)\n",
    "        \n",
    "        #tracé courbe PNSR en fonction de la translation\n",
    "        PSNR = hv.Curve(P,\"Translation\",\"PSNR\", label = \"Tracé des valeurs de PSNR \\n pour différentes translations\").opts(width=300,height=300)\n",
    "        \n",
    "        #définition des images        \n",
    "        Ioriginal = hv.Image(S, label = \"Image orinigale\").opts(cmap='gray',width=350,height=350)\n",
    "        Ibuite = hv.Image(SB,label = \"Image bruitée\").opts(cmap='gray',width=350,height=350) \n",
    "        Idebruite = hv.Image(Srec,label = \"Image débruitée\").opts(cmap='gray',width=350,height=350)\n",
    "        \n",
    "        return pn.Column(PSNR, pn.Row(Ioriginal,pn.Column (Ibuite, \"PSNR entre image bruitée et image originale: \",P_Buite)\n",
    "                                ,pn.Column (Idebruite, \"PSNR moyen (sur les translations) entre \\n image débruitée et image originale: \",P_moy)))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DebruitTranslat = Debruit_translat()\n",
    "pn.Row(DebruitTranslat.param,DebruitTranslat.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Débruitage d'une image couleur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour effectuer le débruitage d'une image générale, c'est à dire d'une image couleur dont le format n'est pas carré et dont les dimensions ne sont pas des puissnaces de 2 on procède comme suit :\n",
    "\n",
    "1) On effectue un débruitage séparé sur chacun des canaux.\n",
    "\n",
    "2) Le format carré n'est pas un vraiu problème, il faut juste que les dimensions soit des multiples de puissances de \n",
    "2. C'est la puissance de 2 qui définira l'échalle maximale de la décomposition en ondelettes. Il est donc préférable que les dimensions de l'images soient un petit multiple d'une puissance de 2.\n",
    "\n",
    "3) On étend l'image par symétrie ou périodicité pour qu'elle ait les dimensions souhaitées. A la fin du processus de débruitage on tronque le résultat obtenu à la dimension de l'image originale.\n",
    "\n",
    "4) Si le niveau de bruit n'est pas connu, il faut l'estimer en utilisant les coefficients d'ondelettes de la plus petite échelle (voir le notebook sur le débruitage de signaux).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposer une fonction qui effectue le débruitage d'une image couleur de dimensions quelconques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction peut prendre en entrée un tableau numpy ou une image dans une format d'images classique.\n",
    "Vous pouvez tester votre programme en bruitant vous même une ou plusieurs images de référence et évaluer le gain en terme de PSNR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pour aller plus loin (à titre informatif et optionnel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut améliorer les méthodes par seuillage dans une base d'ondelettes en effectuant un seuillage par blocs. C'est à dire, ne pas décider de conserver ou pas un coefficients en fonction de sa seule amplitude mais plutôt en fonction de l'énergie d'un voisinage de coefficients. \n",
    "\n",
    "Voir : http://www.cnrs.fr/insmi/spip.php?article265\n",
    "\n",
    "En effet, il est rare qu'un coefficient soit significatif seul au milieu de coefficients nuls. \n",
    "\n",
    "La mméthode de sueillage par blocs consiste à choisir une taille de voisinage (par exemple 4*4 coeffients en dimension 2) pour une échelle et une direction donnée et de conserver l'intégralité des coefficients si l'énergie (la somme des carrés des coefficients) est supérieure à un seuil et de les mettre tous à 0 si ce n'est pas le cas. \n",
    "\n",
    "Dans ce cas aussi, les translations permettent d'améliorer le rendu visuel en limitant les effets de blocs.\n",
    "\n",
    "On peut aussi constuire des blocs \"3D\" en considérant des blocs qui comprennent les coefficients des 3 créneaux de couleurs. L'idée est de corréler le débruitage un peu à travers l'espace et l'espace des couleurs.\n",
    "\n",
    "Il est possible d'effectuer un débruitage en changeant d'espace colorimétrique en passant du RGB au YUV par exemple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Débruiter un minotaure ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A l'aide de tout ce qui a été fait précédemment, proposer une version débruitée de l'image couleur contenue dans le tableau Mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mi = chargeData('Minotaure')\n",
    "Minotaure=np.clip(Mi,0,255)\n",
    "hv.RGB(Minotaure.astype('uint8')).opts(xlabel=None,ylabel=None,width=400,height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DebruitTrans_Couleurs(im,qmf,L,T,sigma,NbT):\n",
    "    n1,n2,n3=np.shape(im)\n",
    "    Seuil=T*sigma\n",
    "    ISum=np.zeros(np.shape(im))\n",
    "    Srec=np.zeros(np.shape(im))\n",
    "    P=np.zeros(NbT)\n",
    "    for j in range(n3):\n",
    "        ib=im[:,:,j]\n",
    "        for k in np.arange(0,NbT):\n",
    "            #Translation des lignes et des colonnes de l'image\n",
    "            SBtemp=np.roll(ib,k,axis = 1) #décalage des colonnes\n",
    "            SBtemp=np.roll(SBtemp,k,axis = 0) #décalage des lignes\n",
    "            #Seuillage sur l'image translatée\n",
    "            Srectemp=SeuillageDurOndelettes(SBtemp,qmf,L,Seuil)\n",
    "            #Translation des lignes et des colonnes inverse\n",
    "            Srectemp2=np.roll(Srectemp,-k,axis = 1)\n",
    "            Srectemp2=np.roll(Srectemp2,-k,axis = 0)      \n",
    "            ISum[:,:,j]=ISum[:,:,j]+Srectemp2\n",
    "            Srec[:,:,j]=ISum[:,:,j]/(k+1)\n",
    "    return Srec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Resize_debruit(ib,qmf,L,T,sigma,NbT): \n",
    "    n1,n2,n3 = np.shape(ib) \n",
    "      \n",
    "    if n1 < n2 : \n",
    "        CaSym = np.zeros((max(n1,n2),max(n1,n2),n3))\n",
    "        ib_ =  np.flip(ib,axis=0)[:(n2-n1),:,:] \n",
    "        CaSym[n1::,:,:] = ib_\n",
    "        CaSym[:n1,:,:] = ib\n",
    "        \n",
    "        Srec = DebruitTrans_Couleurs(CaSym,qmf,L,T,sigma,NbT)[:n1,:,:]\n",
    "    \n",
    "    if n1 > n2 : \n",
    "        CaSym = np.zeros((max(n1,n2),max(n1,n2),n3))\n",
    "        result = np.zeros((max(n1,n2),max(n1,n2),n3))\n",
    "        ib_ =  np.flip(ib,axis=1)[:,:(n1-n2),:] \n",
    "        CaSym[:,n2::,:] = ib_\n",
    "        CaSym[:,:n2,:] = ib     \n",
    "        \n",
    "        Srec = DebruitTrans_Couleurs(CaSym,qmf,L,T,sigma,NbT)[:,:n2,:] \n",
    "    \n",
    "    if n1 == n2 : \n",
    "        Srec = DebruitTrans_Couleurs(ib,qmf,L,T,sigma,NbT)\n",
    "    \n",
    "    return Srec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Debruit_translat_Minotaure(param.Parameterized):\n",
    "    wave = param.ObjectSelector(default=\"db2\",objects=wavelist)\n",
    "    NbT = param.Integer(4,bounds=(1,8))\n",
    "    Sigma = param.Number(10,bounds=(1,100))\n",
    "    L = param.Integer(7,bounds=(0,7))\n",
    "    T=param.Number(3,bounds=(0,8))\n",
    "    def view(self):\n",
    "        S = Mi\n",
    "        Minotaure=np.clip(Mi,0,255)\n",
    "        Srec=Resize_debruit(S,self.wave,self.L,self.T,self.Sigma,self.NbT)\n",
    "        MinotaureRec=np.clip(Srec,0,255)\n",
    "        \n",
    "        #définition des images :    \n",
    "        Ibruite = hv.RGB(Minotaure.astype('uint8'),label=\"Image bruitée originale\").opts(xlabel=None,ylabel=None,width=350,height=350)\n",
    "        Idebruite = hv.RGB(MinotaureRec.astype('uint8'),label = \"Image débruitée\").opts(xlabel=None,ylabel=None,width=350,height=350)\n",
    "    \n",
    "        return pn.Column(pn.Row(Ibruite,Idebruite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DebruitTranslatMinotaure = Debruit_translat_Minotaure()\n",
    "pn.Row(DebruitTranslatMinotaure.param,DebruitTranslatMinotaure.view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deb=DebruitTrans_Couleurs(Minotaure,'db2',7,4.2,30,8)\n",
    "hv.RGB(deb.astype('uint8')).opts(xlabel=None,ylabel=None,width=400,height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>Ceci est un exemple d'une image minotaure débruitée initialement bruitée.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rédiger également une fonction prenant en entrée un nom de fichier \n",
    "permettant de calculer le PSNR de votre proposition d'image débruitée avec l'image en question.\n",
    "On calcule le PSNR entre deux images couleurs en calculant la somme des erreurs quadratiques sur les 3 canaux.\n",
    "\n",
    "Attention, l'image a 3 canaux de couleur, n'est pas carrée et les dimensions ne sont pas des puissances de 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan d'expériences pour évaluer l'impact des translations  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un plan d'expériences pour explorer les performances de l'invariance par translation pour le débruitage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiences_DebruitTrans = {'Image':imagesRef.keys(),'NbT':np.arange(1,5),'wave':wavelist,'Sigma':np.linspace(10,30,2)}\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfexp_DebruitTrans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui calcule le PSNR moyen sur n réalisations de bruit du débruitage d'une image avec NbT*NbT translations (qui utilise par exemple la fonction DebruitTranslation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Debruit_Translat_PSNRMoyen(I,wave,sigma,NbT,n):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire la fonction qui à une ligne de la base de données précédente calcule le PSNR moyen sur 4 réalisations du bruit. Puis l'appliquer à la base de données et ajouter la colonne des PSNR calculés à la base de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row2DebruitTrans(row):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliser hvplot pour visualiser les résulatst contenus dans la base de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantification et Entropie de Shannon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShannonEntropy(x):\n",
    "    value,counts = np.unique(x, return_counts=True)\n",
    "    Proba=counts/len(x)\n",
    "    Ent=-np.sum(np.log2(Proba)*Proba)\n",
    "    return Ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([13,13,2,7,13,7,1,13])\n",
    "print(ShannonEntropy(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array([-2,-3,1,0,1,0,-2,-3])\n",
    "print(ShannonEntropy(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui effectue la quantification de la transformée en ondelettes avec un pas \"Pas\". On pourra à nouveau utiliser la commande pywt.ravel_coeffs. La fonction doit renvoyer l'image calculée par quantification, le PSNR associé ainsi que le nombre d'octets estimé par la valeur de l'entropie a priori nécessaire pour coder une telle image. On considérera qu'on code séparément les coefficients d'échelle et les coefficients d'ondelettes. Tester la fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QuantificationOndelettes(I,qmf,Pas):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer le dashboard asscoié à la focntion précédente. \n",
    "Le dashboard doit renvoyer l'image quantifiée, le PSNR de l'image ainsi que le facteur de compression théorique associé. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveQuant(param.Parameterized):\n",
    "    wave = param.ObjectSelector(default=\"haar\",objects=wavelist)\n",
    "    QS = param.Number(30,bounds=(10,300))\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer dun plan d'expériences pour comparer les différentes ondelettes pour la quantification... et poursuivre jusqu'à obtenir un affichage de la base de données ainsi créée avec hvplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiences_quant = {'QS':np.linspace(30,200,10),'wave':wavelist}\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row2DistorsionRate(row):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pour aller plus loin (à titre informatif et optionnel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous proposons ici d'effectuer la compression sur les 3 canau RGB. Or l'oeil humain est plus sensible à la luminance qu'aux composantes purement chromatiques. C'est pourquoi, la plupart des algorithmes de compressions sont effectué dans un espace colorimétrique YUV où Y est la luminance. On alloue alors plus d'information au canal Y et on comprime plus drastiquement les deux autres canaux. Une méthode standart consiste par exemple à sous-échantionner d'un facteur 2 les deux composantes U et V avant de les comprimer. \n",
    "\n",
    "https://fr.wikipedia.org/wiki/Sous-échantillonnage_de_la_chrominance\n",
    "\n",
    "On obtient alors des images de chrominances moins résolues et donc moins lourdes mais le rendu final reste correct car l'oeil humain est nettement plus sensible à la luminance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
