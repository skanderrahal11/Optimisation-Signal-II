{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TP 2 - Echantillonnage compressif\n",
    "=================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <Font color = \"blue\"> ENGELSEN Gorm et RAHAL Skander"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import scipy.fftpack as fft\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import linalg as npl\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RÃ©cemment (dÃ©but annÃ©es 2004-prÃ©sent), de nouveaux concepts et thÃ©orÃ¨mes ont Ã©tÃ© dÃ©veloppÃ©s et risquent de \n",
    "rÃ©volutionner Ã  relativement court terme la fabrication de certains appareils de mesure numÃ©riques (microphones, imageurs, analyseurs de spectres,...). \n",
    "Ces nouvelles techniques sont couramment appelÃ©es Ã©chantillonnage compressif, \"compressive sampling\" ou encore \"compressed sensing\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Le thÃ©orÃ¨me de Shannon"
   ]
  },
  {
   "attachments": {
    "EchantillonageSous_Nyquist.png": {
     "image/png": "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"
    },
    "Echantillonnage09.png": {
     "image/png": "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"
    },
    "Echantillonnage105.png": {
     "image/png": "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"
    },
    "Echantillonnage201.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aujourd'hui, presque tous les appareils de mesure reposent sur le thÃ©orÃ¨me de Shannon. Celui-ci (vous l'avez dÃ©jÃ  vu en 2Ã¨me annÃ©e) peut s'Ã©noncer ainsi : \n",
    "> Soit $g:\\mathbb{R}\\to \\mathbb{R}$ une fonction de $L^2(\\mathbb{R})$. Si sa transformÃ©e de Fourier $\\hat g$ a un support contenu dans l'intervalle $[-f_M, f_M]$, alors en l'Ã©chantillonnant Ã  une frÃ©quence d'Ã©chantillonnage $f_e\\geq 2f_M$, on peut la reconstruire exactement.\n",
    "\n",
    "Ce thÃ©orÃ¨me est illustrÃ© sur les figures ci-aprÃ¨s:\n",
    "![Echantillonnage105.png](attachment:Echantillonnage105.png)![Echantillonnage201.png](attachment:Echantillonnage201.png)\n",
    "![Echantillonnage09.png](attachment:Echantillonnage09.png)![EchantillonageSous_Nyquist.png](attachment:EchantillonageSous_Nyquist.png)\n",
    "\n",
    "Les instruments de mesures qui reposent sur ce thÃ©orÃ¨me sont donc construits suivant le principe : \n",
    ">Filtre passe-bas $\\rightarrow$ Echantillonnage Ã  une frÃ©quence $f>2f_M$ $\\rightarrow$ Interpolation sinc\n",
    "\n",
    "Pour beaucoup d'applications, ce principe prÃ©sente deux dÃ©fauts majeurs :\n",
    "* Les signaux sont rarement naturellement Ã  spectre bornÃ©, et on perd donc l'information haute-frÃ©quence en effectuant un filtrage passe-bas.\n",
    "* Pour beaucoup de signaux, il faut choisir une trÃ¨s haute frÃ©quence d'Ã©chantillonnage pour obtenir un rÃ©sultat satisfaisant. \n",
    "Ceci implique que les donnÃ©es Ã  stocker ont une taille trÃ¨s importante et qu'il faut les compresser aprÃ¨s coup (par exemple : jpeg).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. L'Ã©chantillonnage compressif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Principe gÃ©nÃ©ral**\n",
    "\n",
    "L'idÃ©e sous jacente Ã  l'Ã©chantillonnage compressif est de rÃ©aliser la compression dÃ¨s l'acquisition.\n",
    "Supposons que le signal $x\\in \\mathbb{R}^n$ que l'on souhaite mesurer s'Ã©crive comme une combinaison linÃ©aire de la forme :\n",
    "\\begin{equation}\n",
    "(1)~~~~~~~~~~~ x=\\sum_{i=1}^m\\alpha_i \\psi_i\n",
    "\\end{equation}\n",
    "oÃ¹ $\\psi_i\\in \\mathbb{R}^n, \\ i=1..m$, sont des \"fonctions de base\" (en traitement d'images, ces fonctions pourraient Ãªtre des ondelettes, en traitement du son, des ondelettes ou des atomes de Fourier, pour certaines applications, on pourrait imaginer des splines...} et $\\alpha_i\\in \\mathbb{R}$ sont des coefficients. \n",
    "On peut rÃ©Ã©crire l'Ã©quation (1) sous la forme matricielle condensÃ©e :\n",
    "$$\n",
    "x=\\Psi \\alpha \\ \\ \\textrm{oÃ¹ } \\ \\ \\alpha=\\begin{pmatrix} \\alpha_1 \\\\ \\vdots \\\\ \\alpha_m \\end{pmatrix}\\ \\ \\textrm{et} \\ \\ \\Psi=\\begin{pmatrix} \\psi_1,\\psi_2,..., \\psi_m\\end{pmatrix}.\n",
    "$$\n",
    "Pour pouvoir reconstruire tous les Ã©lÃ©ments de $\\mathbb{R}^n$, on suppose gÃ©nÃ©ralement que la matrice $\\Psi$ est une matrice surjective (ainsi, la famille  des $(\\Psi_i)_i$ est gÃ©nÃ©ratrice), ce qui implique que $m\\geq n$. Dans le langage du traitement d'image, on dit alors que $\\Psi$ est un frame (une base si $m=n$).\n",
    "\n",
    "L'Ã©chantillonnage compressif repose sur l'hypothÃ¨se suivante : les signaux $x$ que l'on souhaite mesurer sont parcimonieux, \n",
    "c'est-Ã -dire que la majoritÃ© des coefficients $\\alpha_i$ dans (1) sont nuls ou encore que \n",
    "$$\\#\\{\\alpha_i\\neq 0, i=1..m\\}\\ll n.$$\n",
    "On va voir que cette hypothÃ¨se permet - dans certains cas - de rÃ©duire drastiquement le nombre de mesures par rapport au thÃ©orÃ¨me de Shannon avec en contre-partie, le besoin de rÃ©soudre un problÃ¨me d'optimisation pour reconstruire la donnÃ©e. L'objectif de ce TP est de rÃ©soudre le problÃ¨me d'optimisation rÃ©sultant.\n",
    "\n",
    "Le principe de l'acquisition du signal $x$ est le suivant :\n",
    "\n",
    "- On effectue un petit nombre $p\\ll n$ de mesures linÃ©aires du signal $x$ inconnu. On note ces mesures $y_i$, et comme elles sont linÃ©aires par rapport Ã  $x$, il existe pour chaque $i$ un vecteur $a_i\\in \\mathbb{R}^n$ tel que \n",
    "$$y_i=\\langle a_i, x\\rangle, i=1..p.$$ On peut aussi Ã©crire cette opÃ©ration de mesure sous la forme condensÃ©e :\n",
    "$$\n",
    "y=Ax\\ \\ \\textrm{oÃ¹ } \\ \\ y=\\begin{pmatrix} y_1 \\\\ \\vdots \\\\ y_p\\end{pmatrix} \\ \\ \\textrm{et} \\ \\ A=\\begin{pmatrix} a_1^T\\\\a_2^T\\\\ \\vdots\n",
    "\\\\ a_p^T\\end{pmatrix}.\n",
    "$$\n",
    "- On reconstruit le signal $x$ en rÃ©solvant le problÃ¨me contraint suivant :\n",
    "\n",
    "$$\n",
    "(2)~~~~~~~~~~~ \\mbox{Trouver } \\alpha^\\star \\mbox{ solution de: }\\displaystyle\\min_{\\alpha \\in \\mathbb{R}^m, A\\Psi\\alpha=y} \\|\\alpha\\|_0\n",
    "$$\n",
    "\n",
    "oÃ¹ $\\|\\cdot\\|_0$ est la norme de comptage, aussi appelÃ©e norme $l^0$ dÃ©finie par : \n",
    "$$\n",
    "\\|\\alpha\\|_0=\\#\\{\\alpha_i\\neq 0, i=1..m\\}.\n",
    "$$\n",
    "Autrement dit, l'idÃ©e est la suivante : on  cherche $\\alpha^\\star$, le signal le plus parcimonieux dans le frame $\\Psi$, parmi les signaux qui peuvent donner lieu aux mesures $y$. \n",
    "AprÃ¨s avoir trouvÃ© $\\alpha^\\star$, on recouvre $\\tilde x$, une approximation du signal $x$ en calculant $\\tilde x=\\Psi\\alpha^\\star$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Simplification du problÃ¨me d'optimisation**\n",
    "\n",
    "Le problÃ¨me prÃ©cÃ©dent est un problÃ¨me combinatoire NP-complet, ce qui signifie que trouver $\\alpha$ peut demander un temps exponentiel en fonction de $n$, la dimension du signal. Pour le rÃ©soudre en pratique, il est souvent remplacÃ© par : \n",
    "\n",
    "$$\n",
    "(3)~~~~~~~~~~~  \\mbox{Trouver } \\alpha^*\\in \\displaystyle\\arg\\min_{\\alpha \\in \\mathbb{R}^m, A\\Psi\\alpha=y} \\|\\alpha\\|_1\n",
    "$$\n",
    "\n",
    "oÃ¹ $\\|\\alpha\\|_1=\\sum_{i=1}^m|\\alpha_i|$ est la norme $l^1$ de $\\alpha$. On peut dans certains cas montrer que les solutions de (2) et de (3) sont identiques. \n",
    "\n",
    "Un appareil de mesure n'Ã©tant jamais parfait, il est impossible de mesurer exactement $y_i=\\langle a_i, x\\rangle$. \n",
    "Le vecteur $y$ est bruitÃ© et la contrainte $A\\Psi\\alpha=y$ est trop forte. Elle est donc gÃ©nÃ©ralement relaxÃ©e et le problÃ¨me devient : \n",
    "\n",
    ">$$(4)~~~~~~~~~~~  \\mbox{Trouver } \\alpha^*\\in \\arg\\min_{\\alpha \\in \\mathbb{R}^m} \\|\\alpha\\|_1 + \\frac{\\sigma}{2} \\|A\\Psi\\alpha-y\\|_2^2.$$\n",
    "\n",
    "Si $\\sigma$ tend vers $0$, la solution du problÃ¨me (4) tend vers une solution du problÃ¨me (3). C'est le problÃ¨me (4) que nous allons rÃ©soudre dans ce TP. Dans la suite , on notera $F$ la fonction :\n",
    "$$\n",
    "F(\\alpha)=\\|\\alpha\\|_1 + \\frac{\\sigma}{2} \\|A\\Psi\\alpha-y\\|_2^2.\n",
    "$$\n",
    "\n",
    "On peut remarquer que les problÃ¨mes (3) et (4) sont convexes (contraintes convexes et fonctions convexes) tandis que le problÃ¨me (2) ne l'est pas. En revanche, aucun des trois problÃ¨mes n'est diffÃ©rentiable.\n",
    "\n",
    "Pour conclure cette introduction Ã  l'Ã©chantillonnage compressif, notons que de faÃ§on similaire au thÃ©orÃ¨me de Shannon, on dispose d'une condition de reconstruction exacte :\n",
    "\n",
    "> Supposons que :\n",
    "* $x=\\displaystyle\\sum_{i=1}^m\\alpha_i\\psi_i\\in \\mathbb{R}^n$ avec $\\|\\alpha\\|_0=k$.\n",
    "* On effectue $p$ mesures linÃ©aires de $x$ avec $p\\geq C \\cdot k \\cdot \\log(n)$, oÃ¹ $C=20$.\n",
    "* On choisit les coefficients de la matrice $A\\in \\mathcal{M}_{p,n}$ de faÃ§on **alÃ©atoire** (e.g. on peut choisir les coefficients $a_{i,j}$ de $A$ de faÃ§on indÃ©pendante suivant une loi normale.)\n",
    "\n",
    "> Alors, la rÃ©solution du problÃ¨me (3) permet de reconstruire $x$ **exactement** avec une trÃ¨s grande probabilitÃ© \n",
    "\n",
    "L'expÃ©rience a montrÃ© qu'en pratique, il suffit en gÃ©nÃ©ral de $p=2k$ mesures pour reconstruire le signal exactement en grande dimension !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Algorithme Forward Backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commencons par quelques rappels: soit $F=f+g$ une fonction convexe composite avec $f$ diffÃ©rentiable Ã  gradient \n",
    "$L$-Lipschitz et $g$ une fonction convexe dont on sait calculer l'opÃ©rateur proximal. L'algorithme Forward-Backward s'Ã©crit alors:\n",
    "$$x_{k+1}=prox_{sg}(x_k-s\\nabla f(x_k)).$$\n",
    "\n",
    "On peut montrer que la suite $(F(x_k)-F(x^*))_{k\\in \\mathbb N}$ est dÃ©croissante et: \n",
    "$$F(x_k)-F(x^*)\\leqslant \\frac{2\\Vert x_0-x^*\\Vert^2}{sk}$$\n",
    "Cette vitesse en $\\frac{1}{k}$ est optimale au sens oÃ¹ il n'est pas possible de trouver des bornes qui dÃ©croissent en $\\frac{1}{k^{\\delta}}$ avec $\\delta>1$ pour toutes les fonctions convexes. On peut montrer que si $s<\\frac{1}{L}$ on a en fait \n",
    "$$F(x_k)-F(x^*)=o\\left(\\frac{1}{k}\\right).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revenons maintenant au problÃ¨me (4) et appliquons l'algorithme FB pour le rÃ©soudre. Pour cela: \n",
    "\n",
    "**Q1.** Soit $J(\\alpha) =\\frac{\\sigma}{2}\\|A\\Psi \\alpha - y\\|_2^2$. Calculez $\\nabla J(\\alpha)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "J(\\alpha) &=\\frac{\\sigma}{2}\\|A\\Psi \\alpha - y\\|_2^2\\\\\n",
    "&= \\frac{\\sigma}{2}(A\\Psi \\alpha - y)^T(A\\Psi \\alpha - y)\\\\\n",
    "&= \\frac{\\sigma}{2}(A^T\\Psi^T \\alpha^T - y^T)^T(A\\Psi \\alpha - y)\\\\\n",
    "&= \\frac{\\sigma}{2}(\\alpha^T\\Psi^TA^TA\\Psi\\alpha - \\alpha^T\\Psi^TA^Ty - y^TA\\Psi\\alpha + y^Ty)\\\\\n",
    "\\nabla J (\\alpha) &= \\sigma (A \\Psi)^T (A \\Psi \\alpha - y)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.** Montrer que la fonction $J$ est de classe $C^1$ Ã  gradient Lipschitz et calculer un majorant $L$ de la constante de Lipschitz de $\\nabla J$ en fonction de $|||A|||$, de $|||\\Psi |||$ et de $\\sigma$.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $J$ est de classe $C^1$:\n",
    "\n",
    "$ A\\Psi \\alpha - y $ est linaire et $ ||\\cdot||^2 $ est une norme carrÃ© donc $J(\\alpha)$ est de classe $C^1$\n",
    "\n",
    "#### Gradent Lipschitz:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "||\\nabla J(\\alpha) - \\nabla J(\\beta)|| &= ||\\sigma(A\\Psi)^T(A\\Psi\\alpha-y)-\\sigma(A\\Psi)^T(A\\Psi\\beta-y)||\\\\\n",
    "&= \\sigma||(A \\Psi)^T A \\Psi (\\alpha - \\beta)||\\\\\n",
    "&=\\leq |||(A \\Psi)^T A \\Psi|||\\cdot||\\alpha - \\beta||\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "donc $\\nabla (J)$ est Lipschitz avec $L = \\sigma |||(A \\Psi)^T A \\Psi|||$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.** On note $\\alpha^k$ l'itÃ©rÃ© courant. On veut utiliser l'algorithme Forward-Backward pour la rÃ©solution du problÃ¨me (4) en choisissant un pas constant Ã©gal Ã  $\\frac{1}{L}$. Ecrire une itÃ©ration de l'algorithme FB et donner la formule analytique permettant de calculer\n",
    "$\\alpha^{k+1}$ en fonction de $\\alpha^k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\alpha^{k+1} &= \\mbox{prox}_{\\frac{1}{L}\\left\\|.\\right\\|_1}\\Big(\\alpha^k-\\frac{1}{L}\\nabla J(\\alpha^k)\\Big) \\\\\n",
    "&= \\mbox{prox}_{\\frac{1}{L}\\left\\|.\\right\\|_1}\\Big(\\alpha^k-\\frac{1}{L}\\sigma (A \\Psi)^T (A \\Psi \\alpha^k - y)\\Big)\\\\\n",
    "&=sgn\\Big(\\alpha^k-\\frac{1}{L}\\sigma (A \\Psi)^T (A \\Psi \\alpha^k - y)\\Big)\\cdot max \\Big(\\alpha^k-\\frac{1}{L}\\sigma (A \\Psi)^T (A \\Psi \\alpha^k - y) - \\frac{1}{L}, 0\\Big)\n",
    "\\end{align}\n",
    "$$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Q4.** De quelle quantitÃ© la fonction coÃ»t $F(\\alpha)$ dÃ©croÃ®t-elle Ã  chaque itÃ©ration ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cherche trouver $F(\\alpha^k) - F(\\alpha^{k+1})$ ou \n",
    "$$F(\\alpha) = \\| \\alpha \\|_1 + \\frac{\\sigma}{2}\\|A\\Psi \\alpha - y\\|_2^2 = \\| \\alpha \\|_1 + J(\\alpha).$$\n",
    "On a que une iteration de $\\alpha_k$ est:\n",
    "$$\\alpha^{k+1} = \\mbox{prox}_{\\frac{1}{L}\\left\\|.\\right\\|_1}\\Big(\\alpha^k-\\frac{1}{L}\\nabla J(\\alpha^k)\\Big) = \\arg\\min_{y \\in \\mathbb{R}^m}(\\frac{1}{L}||y||_1+\\frac{1}{2}||y-\\alpha^k+\\frac{1}{L}\\nabla J(\\alpha^k)||_2^2)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a un problÃ¨me d'optimisation non diffÃ©rentiable et convexe. La condition nÃ©cessaire et suffisante d'optimalitÃ© est alors:\n",
    "$$\n",
    "0\\in\\frac{1}{L}\\partial_{||.||_1}(\\alpha^{k+1})+\\alpha^{k+1}-\\alpha^k+\\frac{1}{L}\\nabla J(\\alpha^k) \\\\ \\alpha^k - \\alpha^{k+1} - \\frac{1}{L}\\nabla J(\\alpha^k)\\in \\frac{1}{L}\\partial_{||.||_1}(\\alpha^{k+1}) $$\n",
    "\n",
    "\n",
    "On a par dÃ©finition du sous-gradient\n",
    "$$\n",
    "\\begin{align} \\frac{1}{L}||\\alpha^{k}||_1 &\\geq  \\frac{1}{L}||\\alpha^{k+1}||_1 + <\\alpha^k - \\alpha^{k+1}-\\frac{1}{L}\\nabla J(\\alpha^{k}), \\alpha^{k}-\\alpha^{k+1}>\\\\\n",
    " \\frac{1}{L}(||\\alpha^{k}||_1-||\\alpha^{k+1}||_1 ) &\\geq   <\\alpha^k - \\alpha^{k+1}, \\alpha^{k}-\\alpha^{k+1}> -\\frac{1}{L}<\\nabla J(\\alpha^{k}), \\alpha^{k}-\\alpha^{k+1}> \\\\\n",
    " ||\\alpha^{k}||_1-||\\alpha^{k+1}||_1  &\\geq  L ||\\alpha^k - \\alpha^{k+1}||_2^2 -<\\nabla J(\\alpha^{k}), \\alpha^{k}-\\alpha^{k+1}>\\end{align}$$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puisque $J$ est Ã  gradient L-Lipschitz on a que:\n",
    "\n",
    " $$J(y) - J(x)  \\leq <\\nabla J(x), y-x> + \\frac{L}{2}||x - y||_2^2 $$\n",
    "\n",
    "Si on pose que $y=\\alpha^{k+1}$ et $x=\\alpha^{k}$ on obtient que:\n",
    "\n",
    " $$- <\\nabla J(\\alpha^k), \\alpha^k-\\alpha^{k+1}> \\geq J(\\alpha^{k+1}) - J(\\alpha^k) - \\frac{L}{2}||\\alpha^k - \\alpha^{k+1}||_2^2 $$\n",
    " \n",
    "Et on peut utiliser cette equation dans l'expression au dessus pour obtenir\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "||\\alpha^{k}||_1-||\\alpha^{k+1}||_1  &\\geq  L ||\\alpha^k - \\alpha^{k+1}||_2^2 +J(\\alpha^{k+1}) - J(\\alpha^k) - \\frac{L}{2}||\\alpha^k - \\alpha^{k+1}||_2^2 \\\\\n",
    "||\\alpha^{k}||_1 + J(\\alpha^k)-||\\alpha^{k+1}||_1 - J(\\alpha^{k+1})  &\\geq  L ||\\alpha^k - \\alpha^{k+1}||_2^2 - \\frac{L}{2}||\\alpha^k - \\alpha^{k+1}||_2^2\\\\\n",
    " F(\\alpha^k) - F(\\alpha^{k+1}) &\\geq \\frac{L}{2}||\\alpha^k - \\alpha^{k+1}||_2^2\n",
    "\\end{align}$$\n",
    "\n",
    "\n",
    "Donc la fonction coÃ»t ð¹(ð›¼) dÃ©croÃ®t d'au moins $\\frac{L}{2}||\\alpha^k - \\alpha^{k+1}||_2^2$ Ã  chaque itÃ©ration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Partie expÃ©rimentale. Les donnÃ©es\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce TP, on va chercher Ã  reconstruire un signal unidimensionnel $x~:~[0,1]~\\rightarrow~\\mathbb{R}$ de la forme :\n",
    "$$\n",
    "x(t)= \\alpha_{k}\\delta_{k/n}(t)+\\sum_{k=1}^n\\alpha_{k+n}\\cos\\left(\\frac{2k\\pi}{n} t\\right)\n",
    "$$ \n",
    "on a donc $m=2n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialisations\n",
    "n=500            #Taille de l'echantillon\n",
    "t=np.linspace(0,1,n) #On definit un signal sur [0,1]\n",
    "\n",
    "## Generation du signal\n",
    "x=np.zeros(n)\n",
    "tmp=np.zeros(n)\n",
    "#On ajoute deux cosinus\n",
    "tmp[350]=4\n",
    "x+=fft.idct(tmp,norm='ortho')  \n",
    "tmp=np.zeros(n)\n",
    "tmp[150]=-3  \n",
    "x+=fft.idct(tmp,norm='ortho')\n",
    "#On ajoute deux diracs\n",
    "x[int(n/3)]=0.2;    #Tester 0.5\n",
    "x[int(2*n/3)]=-0.3; #Tester -1\n",
    "\n",
    "plt.plot(t,x,'b')\n",
    "plt.show()\n",
    "## Mesure du signal\n",
    "p=20*4       #Nombre de mesures\n",
    "A=np.random.randn(p,n) #La matrice de mesure\n",
    "y=A.dot(x)        #Les mesures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code *Generesignal.py* gÃ©nÃ¨re un signal discret $x$ qui peut Ãªtre vu comme une combinaison linÃ©aire de cosinus Ã  diffÃ©rentes frÃ©quences et de diracs. Ce signal n'est pas parcimonieux dans la base canonique des diracs (car il faut Ã  peu prÃ¨s $n$ diracs pour reprÃ©senter un cosinus) et il n'est pas parcimonieux dans la base des sinus (il faut faire une combinaison linÃ©aire de $n$ cosinus pour reprÃ©senter un dirac).\n",
    "\n",
    "Par contre, ce signal est parcimonieux dans un frame qui est l'union de la base canonique et de la base des cosinus. \n",
    "Dans ce frame, il suffit en effet de $4$ coefficients non nuls pour reconstruire parfaitement le signal.\n",
    "\n",
    "> On choisira donc le frame reprÃ©sentÃ© par une matrice $\\Psi=(I,C) \\in \\mathcal{ M}_{2n,n}(\\mathbb{R})$ o\\`u $C$ est une base de cosinus Ã  diffÃ©rentes frÃ©quences.\n",
    "\n",
    "#### 4.2. ImplÃ©mentation de l'itÃ©ration proximale\n",
    "\n",
    "**Q5** ImplÃ©mentez l'opÃ©rateur linÃ©aire $\\Psi$ et son adjoint $\\Psi^*$. \n",
    "\n",
    "Pour $\\Psi$, vous vous servirez de la fonction $dct$ de Python dans la libraire scipy.fftpack qui calcule la transformÃ©e en cosinus discret d'un vecteur. Vous ferez attention Ã  prÃ©ciser *norm='ortho'* dans les options de la $dct$ pour que $idct$ soit bien l'opÃ©ration inverse de $dct$.\n",
    "\n",
    "Pour $\\Psi^*$, vous utiliserez le fait que la $dct$ est une isomÃ©trie quand on prÃ©cise \\textit{norm='ortho'} dans les options de $dct$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Linear function Psi\n",
    "## (combination of sines and diracs) \n",
    "def Psi(alpha) :\n",
    "    n = int(len(alpha)/2)\n",
    "    C = fft.idct(alpha[n:], norm='ortho') \n",
    "    I = alpha[:n]\n",
    "    return I + C\n",
    "\n",
    "## The transpose of Psi\n",
    "def PsiT(x) :\n",
    "    n = len(x)\n",
    "    alpha = np.zeros(2*n)\n",
    "    alpha[:n] = x\n",
    "    alpha[n:] = fft.dct(x, norm='ortho')\n",
    "    return alpha\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6** ImplÃ©mentez l'algorithme proximal dans la fonction *RestoreX* avec les notations suivantes:\n",
    "* $A$ est la matrice d'Ã©chantillonnage.\n",
    "* $y$ est le vecteur de mesures.\n",
    "* $sigma$ est un paramÃ¨tre du modÃ¨le.\n",
    "* $nit$ est le nombre d'itÃ©rations.\n",
    "* $alpha$ est la solution approximative du problÃ¨me (4).\n",
    "* $x$ est donnÃ© par Psi $(\\alpha)$.\n",
    "* $CF$ est la fonction coÃ»t Ã  chaque itÃ©ration de l'algorithme. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prox of the l1âˆ’norm \n",
    "def prox(alpha,gamma) :\n",
    "    beta = np.sign(alpha)*np.maximum(np.abs(alpha) - gamma, 0)\n",
    "    return beta\n",
    "\n",
    "def cost_function(alpha, sigma, A, y):\n",
    "    return npl.norm(alpha,1) + sigma/2*npl.norm(A.dot(Psi(alpha))-y,2)**2\n",
    "\n",
    "\n",
    "def RestoreX(A,y,sigma,nit):\n",
    "    t0 = time.time()\n",
    "    n = np.shape(A)[1]\n",
    "    x = np.zeros(n)\n",
    "    alpha = np.zeros(2*n)\n",
    "    alpha_arr = []\n",
    "    CF = []\n",
    "    L = 2*sigma*npl.norm(A.T@A,2)\n",
    "    gamma = 1/L\n",
    "    \n",
    "    for i in range(nit):\n",
    "        gradJ = sigma * PsiT((A.T).dot(A@Psi(alpha) - y))\n",
    "        x_k = alpha - gamma*gradJ\n",
    "        alpha = prox(alpha - gamma*gradJ, gamma)\n",
    "        CF.append(cost_function(alpha, sigma, A, y))\n",
    "        alpha_arr.append(alpha)\n",
    "        if (i > 1):\n",
    "            if (max(abs(alpha_arr[i] - alpha_arr[i-1])) < 10e-8):\n",
    "                x = Psi(alpha)\n",
    "                t = time.time() - t0\n",
    "                return alpha,x,np.array(CF), alpha_arr, t, i+1\n",
    "\n",
    "    x = Psi(alpha)\n",
    "    t = time.time()-t0\n",
    "    return alpha,x,np.array(CF), alpha_arr, t, i+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7.** Testez votre algorithme ! Les paramÃ¨tres $sigma$ et $nit$ sont des Ã  choisir par vous-mÃªme (il faut en pratique beaucoup d'itÃ©rations pour converger). Vous pourrez observer la faÃ§on dont la suite $\\alpha^k$ se comporte au fur et Ã  mesure des itÃ©rations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1\n",
    "nit = 10000\n",
    "alpha,xtilde,CF, alpha_k, runtime , it = RestoreX(A,y,sigma,nit)\n",
    "print(runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.where(alpha != 0)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize = (15,10))\n",
    "ax[0].set_title(\"Alpha coefficients\")\n",
    "ax[0].plot(alpha)\n",
    "ax[1].set_title(\"Alpha_k coefficients\")\n",
    "ax[1].plot(alpha_k)\n",
    "plt.show()\n",
    "\n",
    "print(\"Alpha coefficients: \", str(l[0].flatten()))\n",
    "a_v = []\n",
    "for i in l[0].flatten():\n",
    "    a_v.append(round(alpha[i],3))\n",
    "    \n",
    "\n",
    "print(\"Alpha values: \", str(a_v))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Commentaire\n",
    "On peut facilement voir que les 4 coefficients non nuls sont $166, 333, 650$ et $850$.\n",
    "A droite, on peut constater la convergence de coefficients de $\\alpha$.Cela nÃ©cessite environ 4500 itÃ©rations Ã  l'algorithme pour qu'il puisse converger.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nit = 10000\n",
    "Sigma = [0.1, 1, 10, 100]\n",
    "alpha_1,xtilde_1,CF_1, alpha_k_1, t1, it1=RestoreX(A,y,Sigma[0],nit)\n",
    "alpha_2,xtilde_2,CF_2, alpha_k_2, t2, it2=RestoreX(A,y,Sigma[1],nit)\n",
    "alpha_3,xtilde_3,CF_3, alpha_k_3, t3, it3=RestoreX(A,y,Sigma[2],nit)\n",
    "alpha_4,xtilde_4,CF_4, alpha_k_4, t4, it4=RestoreX(A,y,Sigma[3],nit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4,3, figsize = (12,17))\n",
    "fig.suptitle(\"Comparison of different sigma\", size = 20)\n",
    "ax[0][0].plot(alpha_1)\n",
    "ax[0][0].set_title(\"Alpha coefficients with $\\sigma = $\" + str(Sigma[0]))\n",
    "ax[0][1].plot(np.log(CF_1))\n",
    "ax[0][1].set_title(\"Log(CF) with $\\sigma = $\" + str(Sigma[0]))\n",
    "ax[0][1].grid()\n",
    "ax[0][2].plot(alpha_k_1)\n",
    "ax[0][2].set_title(\"Convergence of alpha with $\\sigma = $\" + str(Sigma[0]))\n",
    "\n",
    "ax[1][0].plot(alpha_2)\n",
    "ax[1][0].set_title(\"Alpha coefficients with $\\sigma = $\"  + str(Sigma[1]))\n",
    "ax[1][1].plot(np.log(CF_2))\n",
    "ax[1][1].set_title(\"Log(CF) with $\\sigma = $\"  + str(Sigma[1]))\n",
    "ax[1][1].grid()\n",
    "ax[1][2].plot(alpha_k_2)\n",
    "ax[1][2].set_title(\"Convergence of alpha with $\\sigma = $\" + str(Sigma[1]))\n",
    "\n",
    "ax[2][0].plot(alpha_3)\n",
    "ax[2][0].set_title(\"Alpha coefficients with $\\sigma = $\"  + str(Sigma[2]))\n",
    "ax[2][1].plot(np.log(CF_3))\n",
    "ax[2][1].set_title(\"Log(CF) with $\\sigma = $\"  + str(Sigma[2]))\n",
    "ax[2][1].grid()\n",
    "ax[2][2].plot(alpha_k_3)\n",
    "ax[2][2].set_title(\"Convergence of alpha with $\\sigma = $\" + str(Sigma[2]))\n",
    "\n",
    "ax[3][0].plot(alpha_4)\n",
    "ax[3][0].set_title(\"Alpha coefficients with $\\sigma = $\"  + str(Sigma[3]))\n",
    "ax[3][1].plot(np.log(CF_4))\n",
    "ax[3][1].set_title(\"Log(CF) with $\\sigma = $\"  + str(Sigma[3]))\n",
    "ax[3][1].grid()\n",
    "ax[3][2].plot(alpha_k_4)\n",
    "ax[3][2].set_title(\"Convergence of alpha with $\\sigma = $\" + str(Sigma[3]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments:\n",
    "On voit que pour $\\sigma$ trop petit, on risque de sauter des coefficients non nuls et pour $\\sigma$ trop grand , on constate que l'algorithme nÃ©cessite beaucoup de temps avant de converger. Donc on choisit $\\sigma = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8.** VÃ©rifiez que la fonction coÃ»t dÃ©croit de faÃ§on monotone. Quel est le taux de convergence observÃ© ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 2\n",
    "nit = 10000\n",
    "alpha,xtilde,CF, alpha_k , t , it= RestoreX(A,y,sigma,nit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = np.zeros(len(CF)-1)\n",
    "for i in range(len(CF)-1):\n",
    "    dec[i] = CF[i]-CF[i+1]\n",
    "print(\"Minimum value:\" + str(min(dec)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La valeur minimale de la sÃ©quence avec la diffÃ©rence de chaque itÃ©ration est strictement positive. La fonction coÃ»t dÃ©croit de faÃ§on monotone.\n",
    "\n",
    "Ci-dessous on a crÃ©Ã© une fonction pour calculer la taux de convergence observÃ©. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convergence_rate(x, L):\n",
    "    n = len(x[:-1])\n",
    "    diff = np.abs(x[:-1] - L)\n",
    "    ratio = diff[1:] / diff[:-1]\n",
    "    log_ratio = np.log(ratio)\n",
    "    slope, _ = np.polyfit(np.arange(n-1), log_ratio, 1)\n",
    "    rate = np.exp(slope)\n",
    "    return rate\n",
    "\n",
    "print(\"Taux de convergence:\", round(convergence_rate(CF,CF[-1]), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut donc verifier que le taux de convergence observÃ© est en o( $\\frac{1}{k}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q9.** A partir de combien de mesures pouvez-vous reconstruire exactement le signal $x$ ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nit = 10000\n",
    "n = 500\n",
    "sigma = 1\n",
    "p = [80, 40, 30, 20]\n",
    "\n",
    "A1=np.random.randn(p[0],n) \n",
    "y1=A1.dot(x)        \n",
    "alpha_1,xtilde_1,CF_1, alpha_k_1 , t1, it1 =RestoreX(A1,y1,sigma,nit)\n",
    "\n",
    "A2=np.random.randn(p[1],n) \n",
    "y2=A2.dot(x)        \n",
    "alpha_2,xtilde_2,CF_2, alpha_k_2, t2, it2  =RestoreX(A2,y2,sigma,nit)\n",
    "\n",
    "A3=np.random.randn(p[2],n) \n",
    "y3=A3.dot(x)        \n",
    "alpha_3,xtilde_3,CF_3, alpha_k_3, t3, it3  =RestoreX(A3,y3,sigma,nit)\n",
    "\n",
    "A4=np.random.randn(p[3],n) \n",
    "y4=A4.dot(x)        \n",
    "alpha_4,xtilde_4,CF_4, alpha_k_4, t4, it4  =RestoreX(A4,y4,sigma,nit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plotter_2(x, x_tilde, alpha_k, p):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(x_tilde)\n",
    "    plt.title(\"Reconstruction of x with $p = $\" + str(p))\n",
    "    fig, ax = plt.subplots(1,2, figsize = (15,7))\n",
    "    ax[0].plot(np.abs(x-x_tilde))\n",
    "    ax[0].set_title(\" $ |x - x'|$ with $p = $\" + str(p))\n",
    "    ax[1].plot(alpha_k)\n",
    "    ax[1].set_title(\"Convergence of alpha with $p = $\" + str(p))\n",
    "    ax[1].grid()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "plotter_2(x, xtilde_1, alpha_k_1, p[0])\n",
    "\n",
    "plotter_2(x, xtilde_2, alpha_k_2, p[1])\n",
    "\n",
    "plotter_2(x, xtilde_3, alpha_k_3, p[2])\n",
    "\n",
    "plotter_2(x, xtilde_4, alpha_k_4, p[3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commentaire:\n",
    "\n",
    "On voit que pour $ p \\geq 40 $ on peut reconstruire le signal exactement avec une erreur relativement faible.Pour une valeur de $p$ plus grande que 40, on ne peut pas effectivement diminuer l'erreur mais avec une valeur de $p$ infÃ©rieure Ã  40, l'erreur augmente drastiquement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. ImplÃ©mentation de l'itÃ©ration proximale accelÃ©rÃ©e\n",
    "\n",
    "On n'a a aucun moment utilisÃ© la convexitÃ© de la fonction $J$ pour dÃ©finir l'algorithme proximal. Celui-ci est de fait sous-optimal et peut Ãªtre nettement accÃ©lÃ©rÃ©. Yuri Nesterov a proposÃ© dans les annÃ©es 1980 plusieurs mÃ©thodes permettant l'accÃ©lÃ©ration de la descente de gradient explicite. L'accÃ©lÃ©ration de la descente de gradient proposÃ©e Yurii Nesterov en 1984 et adapatÃ©e Ã  FB sous le nom de FISTA (Fast Iterative Soft Shrinckage Algorithm) par Beck et Teboulle en 2009 est d'une mise en oeuvre trÃ¨s simple: considÃ©rons Ã  nouveau la fonction composite $F=f+g$ Ã  minimiser. L'algorithme FISTA s'Ã©crit:\n",
    "\\begin{eqnarray*}\n",
    "y_k &=& x_k+\\alpha_k(x_k-x_{k-1})\\\\\n",
    "x_{k+1} &=& {\\rm prox}_{sg}(y_k-s\\nabla f(x_k))\n",
    "\\end{eqnarray*}\n",
    "\n",
    "avec un pas $s<\\frac{1}{L}$ et $\\alpha_k>0$. On parle de mÃ©thode inertielle car cette mÃ©thode utilise un terme dit de \"mÃ©moire\" ou inertiel qui exploite la derniÃ¨re direction de descente.\n",
    "\n",
    "Le choix original de Nesterov pour la suite $\\alpha_k$ est le suivant :\n",
    "\\begin{equation}\n",
    "\\alpha_k=\\frac{t_k-1}{t_{k+1}}\\text{ avec }t_1=1\\text{ et }t_{k+1}=\\frac{1+\\sqrt{1+t_k^2}}{2}\n",
    "\\end{equation}\n",
    "Pour ce choix on a \n",
    "$$F(x_k)-F(x^*)\\leqslant \\frac{2\\Vert x_0-x^*\\Vert^2}{sk^2}$$\n",
    "On peut prendre plus simplement $$\\alpha_k=\\frac{k-1}{k+2}$$ et dans ce cas, on a $F(x_k)-F(x^*)=o\\left(\\frac{1}{k^2}\\right)$ et on a convergence de la suite $(x_k)_{k\\geqslant 1}$. On peut noter que dans ce cas, la premiÃ¨re Ã©tape est sans inertie ($\\alpha_1=0$) et donc $x_1=T(x_0)$. L'inertie apparait pour le calcul de $x_2$. \n",
    "\n",
    "A noter que la suite de terme gÃ©nÃ©ral $F(x_k)-F(x^*)$ n'est pas nÃ©cessairemment dÃ©croissante comme dans le cas de FB ou de la descente de gradient. Dans la pratique vous verrez que FISTA est quand mÃªme plus rapide que FB.\n",
    "\n",
    " \n",
    "**Q10.** En vous aidant de ce que vous avez codÃ© dans la partie prÃ©cÃ©dente, implÃ©mentez cet algorithme. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Nesterov(A,y,sigma,nit):\n",
    "    t0 = time.time()\n",
    "    n = np.shape(A)[1]\n",
    "    x = np.zeros(n)\n",
    "    alpha = np.zeros(2*n)\n",
    "    alpha_p = np.zeros(2*n)\n",
    "    alpha_arr = []\n",
    "    CF = np.zeros(nit)\n",
    "    L = 2*sigma*npl.norm(A.T@A,2)\n",
    "    gamma = 1/L\n",
    "    for i in range(nit):\n",
    "        tk = (i-1)/(i+2)\n",
    "        \n",
    "        yk = alpha + tk*(alpha - alpha_p)\n",
    "        gradJ = sigma * PsiT((A.T).dot(A@Psi(yk) - y))\n",
    "        alpha_p = alpha\n",
    "        alpha = prox(yk - gamma*gradJ, gamma)\n",
    "        alpha_arr.append(alpha)\n",
    "        CF[i] = cost_function(alpha, sigma, A, y)\n",
    "        if (i > 1):\n",
    "            if (max(abs(alpha_arr[i] - alpha_arr[i-1])) < 10e-5):\n",
    "                x = Psi(alpha)\n",
    "                t = time.time() - t0\n",
    "                return alpha,x,CF, alpha_arr, t, i+1\n",
    "    x = Psi(alpha)\n",
    "    t = time.time() - t0\n",
    "    return alpha,x,CF, alpha_arr, t, i+1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q12.** Testez le et comparez la rapiditÃ© d'execution de l'algorithme prÃ©cÃ©dent et de celui-ci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotter_RvsN(a_r_R, a_r_N, t_N, it_N, t_R, it_R):\n",
    "    \n",
    "    print(\"Runtime Nesterov:    \" + str(round(t_N,4)))\n",
    "    print(\"Iterations Nesterov: \" + str(it_N))\n",
    "    print(\"Runtime RestoreX:    \" + str(round(t_R,4)))\n",
    "    print(\"Iterations RestoreX: \" + str(it_R))\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(1,2, figsize = (15,7))\n",
    "    fig.suptitle(\"$Sigma = $\" + str(sigma) )\n",
    "    ax[0].plot(a_r_R)\n",
    "    ax[0].set_title(\"Alpha coefficients with FISTA\")\n",
    "    ax[0].grid()\n",
    "    ax[0].set_xlabel(\"Iterations\")\n",
    "    ax[1].plot(a_r_N)\n",
    "    ax[1].set_title(\"Alpha coefficients with Forward-Backward\")\n",
    "    ax[1].grid()\n",
    "    ax[1].set_xlabel(\"Iterations\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nit=10000\n",
    "sigma = 0.1\n",
    "alpha_N0,x_N0,CF_N0, a_r_N0, t_N0, it_N0=Nesterov(A,y,sigma,nit)  \n",
    "alpha0,xtilde0,CF0, a_r0, t_R0, it_R0=RestoreX(A,y,sigma,nit)\n",
    "\n",
    "plotter_RvsN(a_r0, a_r_N0, t_N0, it_N0, t_R0, it_R0)\n",
    "\n",
    "sigma = 1\n",
    "alpha_N,x_N,CF_N, a_r_N, t_N, it_N=Nesterov(A,y,sigma,nit)  \n",
    "alpha,xtilde,CF, a_r, t_R, it_R=RestoreX(A,y,sigma,nit)\n",
    "\n",
    "plotter_RvsN(a_r, a_r_N, t_N, it_N, t_R, it_R)\n",
    "\n",
    "sigma = 10\n",
    "alpha_N10,x_N10,CF_N10, a_r_N10, t_N10, it_N10=Nesterov(A,y,sigma,nit)  \n",
    "alpha10,xtilde10,CF10, a_r10, t_R10, it_R10=RestoreX(A,y,sigma,nit)\n",
    "\n",
    "plotter_RvsN(a_r10, a_r_N10, t_N10, it_N10, t_R10, it_R10)\n",
    "\n",
    "sigma = 100\n",
    "alpha_N100,x_N100,CF_N100, a_r_N100, t_N100, it_N100=Nesterov(A,y,sigma,nit)  \n",
    "alpha100,xtilde100,CF100, a_r100, t_R100, it_R100=RestoreX(A,y,sigma,nit)\n",
    "\n",
    "plotter_RvsN(a_r100, a_r_N100, t_N100, it_N100, t_R100, it_R100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir que la methode FISTA est meilleure que celle de Forward-Backward Euler et est moins dÃ©pendante de $\\sigma$. Pour la valeur de $\\sigma$ trop petite, FISTA ne trouve pas toutes les coefficients $\\alpha$ comme Forward-Backward, en revanche elle converge plus rapidement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nit = 10000\n",
    "n = 500\n",
    "sigma = 1\n",
    "p = 25\n",
    "\n",
    "A1=np.random.randn(p,n) \n",
    "y1=A1.dot(x)        \n",
    "alpha_N, xtilde_N,CF_N, alpha_k_N , t1_N, it1_N =Nesterov(A1,y1,sigma,nit)\n",
    "\n",
    "plotter_2(x_N, xtilde_N, alpha_k_N, p)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au-dessus on peut voir qu'avec FISTA on peut reconstruire le signal Ã  partir de $p = 25$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q13.** Faites un rapide rÃ©sumÃ© des points qui vous ont semblÃ© les plus importants dans ce TP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au cours de ce TP, on a  explorÃ© qu'on peut avec un nombre limitÃ© de mesures reconstruire un signal, representer $x$ par ses coefficients $\\alpha \\in \\mathbb{R}^{2n}$ dans une base de cosinus et diraq. On entraÃ®ne un algorithme d'optimisation sur les $\\alpha$ pour trouver les coefficients $\\alpha*$ qui permettent de reconstruire $x$: $x = Psi(\\alpha^*)$.On a comparÃ© principalement deux algorithmes : le Forward-Backward Euler et le FISTA. On a trouvÃ© que FISTA est Ã  la fois plus rapide et meilleur pour la reconstruction du signal malgrÃ© que les deux mÃ©thodes aboutissent aux mÃªmes rÃ©sultats.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
